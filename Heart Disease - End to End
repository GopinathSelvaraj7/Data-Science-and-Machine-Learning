Approach:
1. Problem definition
2. Data
3. Evaluation
4. Features
5. Modelling
6. Experimentation

## 1. Problem definition:
Using the data, can we predict wheather a person has heart disease or not?

## 2. Data:
The original data is taken from UCI/Kaggle repository
https://www.kaggle.com/datasets?search=heart+disease

## 3.Evaluation:
If we can acheive 95% accuracy at predicting wheather or not a patient has hear disease during the proof of concept, we will pursue the project

## 4.Features:
**Only 14 attributes used:

1. #3 (age)
2. #4 (sex)
3. #9 (cp)
4. #10 (trestbps)
5. #12 (chol)
6. #16 (fbs)
7. #19 (restecg)
8. #32 (thalach)
9. #38 (exang)
10. #40 (oldpeak)
11. #41 (slope)
12. #44 (ca)
13. #51 (thal)
14. #58 (num) (the predicted attribute)

Complete attribute documentation:
1 id: patient identification number
2 ccf: social security number (I replaced this with a dummy value of 0)
3 age: age in years
4 sex: sex (1 = male; 0 = female)
5 painloc: chest pain location (1 = substernal; 0 = otherwise)
6 painexer (1 = provoked by exertion; 0 = otherwise)
7 relrest (1 = relieved after rest; 0 = otherwise)
8 pncaden (sum of 5, 6, and 7)
9 cp: chest pain type
-- Value 1: typical angina
-- Value 2: atypical angina
-- Value 3: non-anginal pain
-- Value 4: asymptomatic
10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)
11 htn
12 chol: serum cholestoral in mg/dl
13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)
14 cigs (cigarettes per day)
15 years (number of years as a smoker)
16 fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)
17 dm (1 = history of diabetes; 0 = no such history)
18 famhist: family history of coronary artery disease (1 = yes; 0 = no)
19 restecg: resting electrocardiographic results
-- Value 0: normal
-- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)
-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria
20 ekgmo (month of exercise ECG reading)
21 ekgday(day of exercise ECG reading)
22 ekgyr (year of exercise ECG reading)
23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)
24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)
25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)
26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)
27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)
28 proto: exercise protocol
1 = Bruce
2 = Kottus
3 = McHenry
4 = fast Balke
5 = Balke
6 = Noughton
7 = bike 150 kpa min/min (Not sure if "kpa min/min" is what was written!)
8 = bike 125 kpa min/min
9 = bike 100 kpa min/min
10 = bike 75 kpa min/min
11 = bike 50 kpa min/min
12 = arm ergometer
29 thaldur: duration of exercise test in minutes
30 thaltime: time when ST measure depression was noted
31 met: mets achieved
32 thalach: maximum heart rate achieved
33 thalrest: resting heart rate
34 tpeakbps: peak exercise blood pressure (first of 2 parts)
35 tpeakbpd: peak exercise blood pressure (second of 2 parts)
36 dummy
37 trestbpd: resting blood pressure
38 exang: exercise induced angina (1 = yes; 0 = no)
39 xhypo: (1 = yes; 0 = no)

## Preparing the tools
We are going to use pandas, numpy and Matplotlib for analysis and manipulation

#regular EDA (exploratory data analysis) and plotting libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

#models from scikitlearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier

#model evaluations
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.metrics import plot_roc_curve

## Load data

df = pd.read_csv("heart-disease.csv")
df.head()

## Data Exploration (EDA)
 1. What question(s) are you trying to solve?
 2. What kind of data do we have and how do we treat different types?
 3. What's missing from data and how to deal with?
 4. Where are the outlinears and why should you care about them?
 5. How can you add, change or remove features to get more out of your data?

df.info()

# are there any missing values
df.isna().sum()

df.describe()

## Heart Disease frequency according to Sex

df.sex.value_counts()

#compare target column with sex
pd.crosstab(df.target,df.sex)

#create a plot of crosstab
pd.crosstab(df.target,df.sex).plot(kind="bar",
                                  color=("salmon","lightblue"),
                                  figsize=(10,6));
plt.title("Heart Disease frequency for sex")
plt.xlabel("0=No heart disease, 1=Disease")
plt.ylabel("Amount")
plt.legend(["Female","Male"])
plt.xticks(rotation=0);

## Age vs Max Heart rate

plt.figure(figsize=(10,6))
#scatter with positive sample
plt.scatter(df.age[df.target==1],
            (df.thalach[df.target==1]),
            c="salmon")

#scatter with negative sample
plt.scatter(df.age[df.target==0],
            (df.thalach[df.target==0]),
            c="lightblue")

plt.title("Heart disease in function of age and Max heart rate")
plt.xlabel("Age")
plt.ylabel("Max heart rate")
plt.legend(["Disease","No Disease"]);

# Check the distribution of the age column with histogram
df.age.plot.hist();

## Heart disease freq per chest pain type (cp)
cp: chest pain type
-- Value 1: typical angina
-- Value 2: atypical angina
-- Value 3: non-anginal pain
-- Value 4: asymptomatic

pd.crosstab(df.target,df.cp)

#make the crosstab more visible
pd.crosstab(df.cp,df.target).plot(kind="bar",
                                  figsize=(10,6),
                                  color=["salmon","lightblue"])
plt.title("Heart disease freq per chect pain type")
plt.xlabel("Chest pain type")
plt.ylabel("Amount")
plt.legend(["No Disease","Disease"])
plt.xticks(rotation=0);

# make a correlation matrix
df.corr()

# Using Seaborn make it visual
corr_matrix = df.corr()
fig, ax = plt.subplots(figsize=(15,10))
ax = sns.heatmap(corr_matrix,
                 annot=True,
                 linewidths=0.5,
                 fmt=".2f",
                 cmap="YlGnBu");

## 5. Modelling

#split data into X and y
X = df.drop("target",axis=1)
y = df["target"]

#split data into train and test set
np.random.seed(42)
X_train, X_test, y_train, y_test = train_test_split(X,
                                                    y,
                                                    test_size=0.2)

Now that we got our data ready, we will train the model with train_set and predict with test_set.

We will look into the Scikit learn map to choose our model.

# put modl in dictionary
models = {"Logistic regression": LogisticRegression(),
         "KNN":KNeighborsClassifier(),
         "Random Forest": RandomForestClassifier()}

#create a func to fit and score models
def fit_and_score(models,X_train,X_test,y_train,y_test):
    """ Fits the model on various models and scores them on each"""
    np.random.seed(42)
    #make a n empty dict to store the scoring values
    models_score = {}
    for name,model in models.items():
        model.fit(X_train,y_train)
        models_score[name] = model.score(X_test,y_test)
    return models_score

models_score = fit_and_score(models,
                             X_train=X_train,
                             X_test=X_test,
                             y_train=y_train,
                             y_test=y_test)
models_score

#model comparison 
model_compare = pd.DataFrame(models_score,index=["accuracy"])
model_compare.T.plot.bar()

Now we have got the baseline models, we will tune the model by hyperparameter tuning and perform all evaluation metrics

## Hyperparameter tuning with RandomizedSeachCV

# hyperparameter grid for LogisticRegression
log_reg_grid = {"C": np.logspace(-4,4,20),
                "solver":["liblinear"]}

#hyperparameter grid for RandomForestClassifier
rf_grid = {"n_estimators": np.arange(10,1000,50),
        "max_depth":[None,3,5,10],
        "min_samples_split": np.arange(2,20,2),
        "min_samples_leaf": np.arange(1,20,2)}

#RandomizedSearchCV for LogisticRegression
np.random.seed(42)
ran_search_log = RandomizedSearchCV(LogisticRegression(),
                                    param_distributions=log_reg_grid,
                                    cv=5,
                                    n_iter=20,
                                    verbose=True)

ran_search_log.fit(X_train,y_train)

ran_search_log.best_params_

ran_search_log.score(X_train,y_train)

#RandomizedSearchCV for RandomForestClassifier
ran_search_rf = RandomizedSearchCV(RandomForestClassifier(),
                                   param_distributions=rf_grid,
                                   cv=5,
                                   n_iter=20,
                                   verbose=True)
                                 
ran_search_rf.fit(X_train,y_train)
                                       

ran_search_rf.best_params_

ran_search_rf.score(X_test,y_test)

models_score

## Hyperparameter tuning by GridSearchCV

gs_log_reg = GridSearchCV(LogisticRegression(),
                          param_grid=log_reg_grid,
                          cv=5,
                          verbose=True)

gs_log_reg.fit(X_train,y_train)

gs_log_reg.best_params_

gs_log_reg.score(X_test,y_test)

## Evaluating our Models

#make predictions in order to compare and evaluate
y_preds = gs_log_reg.predict(X_test)

# ROC Curve and AUC

plot_roc_curve(gs_log_reg,X_test,y_test);

#Confusion matrix
print(confusion_matrix(y_test,y_preds))

sns.set(font_scale=1.5)

def plot_conf_mat(y_test,y_preds):
    fig, ax = plt.subplots(figsize=(3,3))
    ax = sns.heatmap(confusion_matrix(y_test,y_preds),
                     annot=True,
                     cbar=False)
    plt.xlabel("True value")
    plt.ylabel("Predicted value")

plot_conf_mat(y_test,y_preds)

# Classification report
print(classification_report(y_test,y_preds))

# cross validation score of precision, recall, f1 by crating a new classifier using best parameters
clf = LogisticRegression(C=0.2043359717859418,
                         solver="liblinear")
np.random.seed(42)

def cv_metrics(clf,X,y):
    cv_acc = cross_val_score(clf,
                         X,
                         y,
                         cv=5,
                         scoring="accuracy")
    cv_pre = cross_val_score(clf,
                             X,
                             y,
                             cv=5,
                             scoring="precision")
    cv_recall = cross_val_score(clf,
                                X,
                                y,
                                cv=5,
                                scoring="recall")
    cv_f1 = cross_val_score(clf,
                            X,
                            y,
                            cv=5,
                            scoring="f1")
    
    return            {"Accuracy":np.mean(cv_acc), 
                       "Precision":np.mean(cv_pre), 
                       "Recall":np.mean(cv_recall), 
                       "F1":np.mean(cv_f1)}

cv_metrics(clf,X,y)

clf = LogisticRegression(C=0.20433,
                         solver="liblinear")
clf.fit(X_train,y_train)

clf.coef_

Match co-eficients of features to columns

feature_dict = dict(zip(df.columns,list(clf.coef_[0])))
feature_dict

feature_df = pd.DataFrame(feature_dict,index=[0])
feature_df.T.plot.bar(title="Feature Importance",legend=False);

## 6. Experimentation

If you havent hit your evaluation metric yet, ask yourself..
* could you collect more data?
* could you try a better model? Like CatBoost or XGBoost?
* could you improve current models?
